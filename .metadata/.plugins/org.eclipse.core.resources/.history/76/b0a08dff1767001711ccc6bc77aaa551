package com.example;

import java.util.Iterator;
import java.util.Map;
import java.util.Map.Entry;

import org.apache.spark.SparkContext;
import org.apache.spark.api.java.JavaPairRDD;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.springframework.beans.factory.annotation.Autowired;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.boot.CommandLineRunner;
import org.springframework.stereotype.Component;

import com.example.model.GroupByFields;
import com.example.model.KafkaInputMessage;
import com.example.model.Result;
import com.example.repository.ResultJdbcRepository;
import com.google.gson.Gson;

import scala.Tuple2;
@Component
public class SparkDataConsumerRunner implements CommandLineRunner{
	@Autowired
	SparkContext sparkContext;
	@Autowired
	private ResultJdbcRepository respository;
	
	@Value("${spark.sql.warehouse.dir}")
	private String SPARK_SQL_WAREHOUSE_DIR;
	
	@Value("${hdfs.folder.location}")
	private String HDFS_FOLDER_LOCATION;

	@Override
	public void run(String... arg0) throws Exception {
		JavaSparkContext sc = new JavaSparkContext(sparkContext);
		while (true) {
			//Extract (E) the data from HDFS
			JavaRDD<String> data = sc.textFile(HDFS_FOLDER_LOCATION);

			//START: Transform (T) the database read from HDFS
			JavaRDD<KafkaInputMessage> resultRecords = data.map(line -> {
				Gson objGson = new Gson();
				KafkaInputMessage rd = objGson.fromJson(line, KafkaInputMessage.class);
				return rd;
			});

			JavaPairRDD<GroupByFields, Integer> rddBrandCount = resultRecords
					.mapToPair(e -> new Tuple2<GroupByFields, Integer>(new GroupByFields(e.getProductbrand(), e.getProductname()), 1));

			JavaPairRDD<GroupByFields, Integer> rddGroupByKeyResult = rddBrandCount.reduceByKey((a, b) -> a + b);
			Map<GroupByFields, Integer> resultMap = rddGroupByKeyResult.collectAsMap();
			//END: Transform (T) the database read from HDFS

			Iterator<Entry<GroupByFields, Integer>> it = resultMap.entrySet().iterator();
			
			//START: Load (L) the transformed data into destination.
			//Here I am saving the transformed result into H2 database. This H2 database is queried by the controller.
			while (it.hasNext()) {
				Entry<GroupByFields, Integer> pair = it.next();
				GroupByFields key = (GroupByFields) pair.getKey();
				Integer value = Integer.parseInt(pair.getValue().toString());

				Result rs = respository.findByProductbrandAndProductname(key.getProductbrand(), key.getProductname());
				if (rs != null) {
					rs.setNumberoforders(value);
				}
				else {
					rs = new Result(key.getProductbrand(), key.getProductname(), value);
				}
				respository.save(rs);
			}
			//END: Load (L) the transformed data into destination.
			
			Thread.sleep(1000 * 60);
		}
	}
		
}
